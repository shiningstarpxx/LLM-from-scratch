# CS336: Language Models From Scratch - 完整学习计划

## 📚 课程概述

**课程名称**: CS336 Language Models From Scratch
**机构**: Stanford University
**学习目标**: 从第一性原理构建语言模型，重点关注效率、规模和系统思维
**核心理念**: Mechanics (工作原理) + Mindset (效率思维) + Intuitions (数据和建模直觉)

## 🎯 学习目标

1. **掌握基础**: 理解语言模型的核心工作原理
2. **系统思维**: 培养对计算资源和效率的敏感度
3. **实践能力**: 能够从零开始构建和优化语言模型
4. **前沿认知**: 了解当前LLM领域的技术栈和发展趋势

## 📅 学习计划 (12周完整安排)

### 第1阶段：基础建立 (第1-2周)

#### **第1周: 课程入门与基础概念**
- **📖 Lecture 01: Introduction & Tokenization**
  - [ ] 课程介绍和历史背景
  - [ ] Tokenization原理与实践
  - [ ] "Bitter Lesson"理念理解
  - [ ] 完成所有编程练习
  - [ ] 整理tokenization实现笔记

- **📖 Lecture 02: PyTorch Building Blocks & Resource Accounting**
  - [ ] 内存和计算基础
  - [ ] Tensor操作和FLOP计算
  - [ ] 资源账务实践
  - [ ] 构建完整训练循环
  - [ ] 性能优化技巧

#### **第2周: 模型架构深入**
- **📖 Lecture 03: Transformer Architecture**
  - [ ] Transformer详细机制
  - [ ] 注意力机制变体
  - [ ] 手动实现简单Transformer
  - [ ] 可视化注意力权重

- **📖 Lecture 04: Mixture of Experts (MoEs)**
  - [ ] 稀疏专家模型原理
  - [ ] 路由机制理解
  - [ ] MoE效率分析
  - [ ] 实现基础MoE层

### 第2阶段：硬件与系统 (第3-4周)

#### **第3周: GPU硬件与性能**
- **📖 Lecture 05: GPU Architecture**
  - [ ] GPU硬件基础
  - [ ] 内存层次结构
  - [ ] 计算单元分析
  - [ ] 性能瓶颈识别

- **📖 Lecture 06: GPU Kernels & Performance Optimization**
  - [ ] GPU架构回顾
  - [ ] 基准测试和性能分析
  - [ ] CUDA内核编写
  - [ ] Triton内核实践
  - [ ] 内核融合优化

#### **第4周: 并行计算基础**
- **📖 Lecture 07: Parallelism Basics**
  - [ ] 分布式计算理论基础
  - [ ] 通信模式分析
  - [ ] 并行算法设计

- **📖 Lecture 08: Distributed Training & Parallelism**
  - [ ] 多GPU训练策略
  - [ ] 数据并行、张量并行、流水线并行
  - [ ] NCCL和集合操作
  - [ ] 通信优化实践

### 第3阶段：规模与优化 (第5-6周)

#### **第5周: 扩展法则**
- **📖 Lecture 09: Scaling Laws Basics**
  - [ ] Chinchilla扩展法则
  - [ ] 计算最优模型规模
  - [ ] 扩展实验设计
  - [ ] 成本效益分析

- **📖 Lecture 10: Inference Optimization**
  - [ ] Transformer推理机制
  - [ ] 算术强度分析
  - [ ] KV缓存优化
  - [ ] 量化和模型压缩
  - [ ] 投机采样和连续批处理

#### **第6周: 高级扩展技术**
- **📖 Lecture 11: Scaling Details**
  - [ ] 高级扩展考虑
  - [ ] 实际大规模训练
  - [ ] 故障处理和容错
  - [ ] 监控和调试

### 第4阶段：应用与评估 (第7-8周)

#### **第7周: 模型评估**
- **📖 Lecture 12: Model Evaluation**
  - [ ] 基准测试全景 (MMLU, HELM, Chatbot Arena)
  - [ ] 知识、指令跟随、推理基准
  - [ ] 安全和能力评估
  - [ ] 评估成本考虑
  - [ ] 设计评估方案

#### **第8周: 推理实战周**
- **💼 实践项目**: 优化一个实际模型的推理
  - [ ] 选择预训练模型
  - [ ] 实现KV缓存优化
  - [ ] 应用量化技术
  - [ ] 性能基准测试
  - [ ] 结果分析和报告

### 第5阶段：数据工程 (第9-10周)

#### **第9周: 训练数据概览**
- **📖 Lecture 13: Training Data Overview**
  - [ ] 历史数据集演进
  - [ ] 数据源分析 (Common Crawl, Wikipedia, 书籍, 代码)
  - [ ] 版权和伦理考虑
  - [ ] 数据作为关键差异化因素

#### **第10周: 数据处理与过滤**
- **📖 Lecture 14: Data Processing & Filtering**
  - [ ] 过滤算法 (KenLM, fastText, DSIR)
  - [ ] 语言识别和质量过滤
  - [ ] 毒性检测
  - [ ] 去重技术 (Bloom filters, MinHash, LSH)
  - [ ] 构建数据处理管道

### 第6阶段：高级训练技术 (第11-12周)

#### **第11周: 对齐技术**
- **📖 Lecture 15: RLHF Alignment**
  - [ ] 人类反馈系统
  - [ ] 对齐技术原理
  - [ ] 奖励模型训练
  - [ ] PPO算法实现

- **📖 Lecture 16: RLVR**
  - [ ] 可验证奖励的强化学习
  - [ ] 数学基础
  - [ ] 实现细节
  - [ ] 与RLHF比较

#### **第12周: 强化学习进阶**
- **📖 Lecture 17: Reinforcement Learning for Language Models**
  - [ ] 策略梯度方法 (PPO, GRPO)
  - [ ] 语言模型RL设置
  - [ ] 可验证奖励和基于结果的奖励
  - [ ] 训练机制和系统考虑
  - [ ] 最终项目设计

## 🎯 每周学习安排

### 每周时间分配 (建议15-20小时)
- **📺 观看讲座**: 3-4小时
- **💻 编程实践**: 6-8小时
- **📝 笔记整理**: 2-3小时
- **🤔 深度思考**: 2-3小时
- **✅ 复习检查**: 1-2小时

### 每日学习节奏
- **工作日**: 2-3小时/天
- **周末**: 4-6小时/天

## 📊 学习里程碑

### 🏁 基础里程碑 (第2周末)
- [ ] 理解tokenization原理
- [ ] 掌握PyTorch基础
- [ ] 实现简单训练循环
- [ ] 理解Transformer架构

### 🔧 系统里程碑 (第4周末)
- [ ] 理解GPU架构原理
- [ ] 掌握性能优化技巧
- [ ] 实现分布式训练基础
- [ ] 能够分析和优化性能瓶颈

### 📈 扩展里程碑 (第6周末)
- [ ] 理解扩展法则
- [ ] 掌握推理优化技术
- [ ] 实现模型压缩
- [ ] 具备大规模训练思维

### 🎯 应用里程碑 (第8周末)
- [ ] 掌握模型评估方法
- [ ] 完成推理优化项目
- [ ] 理解实际部署考虑
- [ ] 具备性能调优能力

### 🗂️ 数据里程碑 (第10周末)
- [ ] 理解数据重要性
- [ ] 掌握数据处理管道
- [ ] 实现各种过滤算法
- [ ] 具备数据工程能力

### 🚀 高级里程碑 (第12周末)
- [ ] 掌握对齐技术
- [ ] 理解强化学习训练
- [ ] 完成综合项目
- [ ] 具备独立研究能力

## 🛠️ 学习工具与环境

### 必备软件
- **Python 3.8+**
- **PyTorch 2.0+**
- **CUDA** (GPU环境)
- **Git** 版本控制

### 核心库
- **深度学习**: torch, torchvision
- **GPU编程**: triton
- **NLP工具**: tiktoken, fasttext, kenlm
- **数据处理**: numpy, pandas, warcio
- **可视化**: matplotlib, wandb
- **分布式**: torch.distributed

### 学习工具
- **笔记**: Obsidian/Notion + Markdown
- **代码**: VS Code + Jupyter
- **版本**: GitHub
- **交流**: Discord/Slack

## 📝 评估方式

### 每周评估
- **编程练习完成度**: 40%
- **笔记质量**: 30%
- **理解深度**: 30%

### 阶段评估
- **基础测试**: 理论知识 + 简单实现
- **系统项目**: 性能优化 + 并行实现
- **应用项目**: 实际问题解决
- **综合项目**: 端到端系统构建

### 最终评估
- **综合项目**: 构建完整的语言模型训练和推理系统
- **技术报告**: 详细的技术分析和优化总结
- **代码审查**: 高质量、可维护的代码实现

## 🎖️ 成功标准

### 优秀水平 (A)
- 完成所有讲座和练习
- 实现所有核心功能
- 具备深度优化能力
- 能够独立设计和实现系统

### 良好水平 (B)
- 完成大部分讲座内容
- 掌握核心概念和技能
- 能够进行基本优化
- 具备实际应用能力

### 及格水平 (C)
- 完成基础讲座内容
- 理解核心概念
- 能够运行和修改代码
- 具备基本应用能力

## 🚀 学习建议

### 学习策略
1. **理论与实践结合**: 每个概念都要编程实现
2. **循序渐进**: 严格按照依赖关系学习
3. **深度优先**: 每个主题都要深入理解
4. **系统思维**: 始终考虑效率和规模

### 注意事项
1. **不要跳过基础**: Lecture 1-2是所有内容的基础
2. **重视硬件理解**: 软硬件结合是现代AI的关键
3. **培养效率意识**: 每行代码都要考虑资源消耗
4. **保持好奇**: 深入探究每个技术背后的原理

### 学习资源
1. **课程仓库**: 当前GitHub仓库
2. **官方文档**: PyTorch, Triton等
3. **论文阅读**: 引用的经典论文
4. **社区交流**: 相关技术社区和论坛

---

**💡 记住**: 这门课的核心是从第一性原理理解语言模型，不要满足于调用API，要深入理解每个组件的工作原理和优化方法。祝你学习愉快！