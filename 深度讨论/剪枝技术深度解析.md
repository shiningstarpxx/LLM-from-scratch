# å‰ªææŠ€æœ¯æ·±åº¦è§£æ

## ğŸ¯ å‰ªææ¨¡å¼æœ¬è´¨ï¼šéç»“æ„åŒ– vs ç»“æ„åŒ–

### âŒ å¸¸è§è¯¯è§£
å¾ˆå¤šäººä»¥ä¸ºå‰ªæå°±æ˜¯ç®€å•åœ°åˆ é™¤æƒé‡çŸ©é˜µçš„è¡Œæˆ–åˆ—ï¼Œè¿™æ˜¯**ä¸å‡†ç¡®**çš„ï¼

### âœ… å‰ªæçš„çœŸå®å«ä¹‰
å‰ªææ˜¯å°†ç¥ç»ç½‘ç»œä¸­çš„æƒé‡**æœ‰é€‰æ‹©æ€§åœ°ç½®é›¶**ï¼Œæ ¹æ®ç½®é›¶æ¨¡å¼åˆ†ä¸ºä¸åŒç±»å‹ã€‚

## ğŸ”¬ å‰ªææ¨¡å¼è¯¦ç»†å¯¹æ¯”

### 1. éç»“æ„åŒ–å‰ªæ (Unstructured Pruning)

```python
import torch
import torch.nn as nn
import torch.nn.utils.prune as prune

def unstructured_pruning_demo():
    """éç»“æ„åŒ–å‰ªææ¼”ç¤º"""

    # åˆ›å»ºä¸€ä¸ªæƒé‡çŸ©é˜µ
    weight = torch.randn(4, 4)
    print("=== åŸå§‹æƒé‡çŸ©é˜µ ===")
    print(weight)

    # åˆ›å»ºçº¿æ€§å±‚
    linear = nn.Linear(4, 4, bias=False)
    linear.weight.data = weight

    # éç»“æ„åŒ–å‰ªæï¼šé›¶æ•£åœ°ç½®é›¶20%çš„æƒé‡
    prune.l1_unstructured(linear, name='weight', amount=0.2)

    print("\n=== éç»“æ„åŒ–å‰ªæå ===")
    print(linear.weight)  # è¢«å‰ªæçš„æƒé‡æ˜¾ç¤ºä¸º0

    # æŸ¥çœ‹å‰ªææ©ç 
    print("\n=== å‰ªææ©ç  ===")
    print(linear.weight_mask)  # 1è¡¨ç¤ºä¿ç•™ï¼Œ0è¡¨ç¤ºå‰ªæ

    # æŸ¥çœ‹åŸå§‹æƒé‡ï¼ˆä»ä¿ç•™ï¼‰
    print("\n=== åŸå§‹æƒé‡ï¼ˆä»ä¿ç•™ï¼‰ ===")
    print(linear.weight_orig)  # åŸå§‹æƒé‡å€¼æœªæ”¹å˜

    # ç»Ÿè®¡ç¨€ç–åº¦
    sparsity = 1.0 - torch.sum(linear.weight_mask).item() / linear.weight_mask.numel()
    print(f"\nå®é™…ç¨€ç–åº¦: {sparsity:.2%}")

    return linear

unstructured_pruning_demo()
```

**ç‰¹ç‚¹**ï¼š
- âœ… **é›¶æ•£ç½®é›¶**ï¼šéšæœºé€‰æ‹©å•ä¸ªæƒé‡å…ƒç´ ç½®é›¶
- âœ… **ç²¾åº¦æŸå¤±å°**ï¼šä¿æŒå¤§éƒ¨åˆ†æƒé‡è¿æ¥
- âŒ **ç¡¬ä»¶ä¸å‹å¥½**ï¼šç¨€ç–çŸ©é˜µéš¾ä»¥åŠ é€Ÿ
- âŒ **å†…å­˜èŠ‚çœæœ‰é™**ï¼šä»éœ€å­˜å‚¨ç¨€ç–ç»“æ„

### 2. ç»“æ„åŒ–å‰ªæ (Structured Pruning)

```python
def structured_pruning_demo():
    """ç»“æ„åŒ–å‰ªææ¼”ç¤º"""

    # åˆ›å»ºæƒé‡çŸ©é˜µ
    weight = torch.randn(4, 4)
    print("=== åŸå§‹æƒé‡çŸ©é˜µ ===")
    print(weight)

    # åˆ›å»ºçº¿æ€§å±‚
    linear = nn.Linear(4, 4, bias=False)
    linear.weight.data = weight

    # ç»“æ„åŒ–å‰ªæï¼šæŒ‰é€šé“ï¼ˆè¡Œï¼‰å‰ªæ20%
    prune.ln_structured(linear, name='weight', amount=0.2, n=2, dim=0)

    print("\n=== ç»“æ„åŒ–å‰ªæåï¼ˆæŒ‰è¡Œï¼‰ ===")
    print(linear.weight)

    print("\n=== å‰ªææ©ç  ===")
    print(linear.weight_mask)

    # ç»Ÿè®¡è¢«å®Œå…¨å‰ªæçš„è¡Œ
    fully_pruned_rows = torch.all(linear.weight_mask == 0, dim=1)
    print(f"\nå®Œå…¨å‰ªæçš„è¡Œ: {fully_pruned_rows}")

    return linear

structured_pruning_demo()
```

**ç‰¹ç‚¹**ï¼š
- âœ… **æ•´ä½“ç½®é›¶**ï¼šåˆ é™¤æ•´ä¸ªç¥ç»å…ƒã€é€šé“æˆ–å±‚
- âœ… **ç¡¬ä»¶å‹å¥½**ï¼šäº§ç”Ÿå¯†é›†çŸ©é˜µï¼Œæ˜“äºåŠ é€Ÿ
- âœ… **å†…å­˜èŠ‚çœå¤§**ï¼šçœŸæ­£å‡å°‘å‚æ•°æ•°é‡
- âŒ **ç²¾åº¦æŸå¤±å¤§**ï¼šåˆ é™¤æ•´ä¸ªç»“æ„è¿æ¥

### 3. ä¸åŒå‰ªææ¨¡å¼çš„å¯è§†åŒ–å¯¹æ¯”

```python
def visualize_pruning_patterns():
    """å¯è§†åŒ–ä¸åŒå‰ªææ¨¡å¼çš„æ•ˆæœ"""

    import matplotlib.pyplot as plt
    import numpy as np

    # åˆ›å»ºç¤ºä¾‹æƒé‡çŸ©é˜µ
    np.random.seed(42)
    weight = np.random.randn(8, 8)

    # æ¨¡æ‹Ÿä¸åŒå‰ªææ¨¡å¼
    def unstructured_prune(matrix, amount):
        """éç»“æ„åŒ–å‰ªæï¼šéšæœºç½®é›¶å•ä¸ªå…ƒç´ """
        mask = np.random.random(matrix.shape) > amount
        return matrix * mask, mask

    def structured_prune_rows(matrix, amount):
        """ç»“æ„åŒ–å‰ªæï¼šæŒ‰è¡Œå‰ªæ"""
        n_rows = int(matrix.shape[0] * amount)
        row_indices = np.random.choice(matrix.shape[0], n_rows, replace=False)
        mask = np.ones_like(matrix, dtype=bool)
        mask[row_indices, :] = False
        return matrix * mask, mask

    def structured_prune_cols(matrix, amount):
        """ç»“æ„åŒ–å‰ªæï¼šæŒ‰åˆ—å‰ªæ"""
        n_cols = int(matrix.shape[1] * amount)
        col_indices = np.random.choice(matrix.shape[1], n_cols, replace=False)
        mask = np.ones_like(matrix, dtype=bool)
        mask[:, col_indices] = False
        return matrix * mask, mask

    # åº”ç”¨ä¸åŒå‰ªææ¨¡å¼
    amount = 0.25  # å‰ªæ25%

    unstructured_result, unstructured_mask = unstructured_prune(weight, amount)
    row_structured_result, row_mask = structured_prune_rows(weight, amount)
    col_structured_result, col_mask = structured_prune_cols(weight, amount)

    # å¯è§†åŒ–
    fig, axes = plt.subplots(2, 4, figsize=(16, 8))

    # åŸå§‹çŸ©é˜µ
    axes[0, 0].imshow(weight, cmap='RdBu', vmin=-2, vmax=2)
    axes[0, 0].set_title('åŸå§‹æƒé‡çŸ©é˜µ')
    axes[1, 0].imshow(np.ones_like(weight), cmap='gray')
    axes[1, 0].set_title('åŸå§‹æ©ç ')

    # éç»“æ„åŒ–å‰ªæ
    axes[0, 1].imshow(unstructured_result, cmap='RdBu', vmin=-2, vmax=2)
    axes[0, 1].set_title('éç»“æ„åŒ–å‰ªæç»“æœ')
    axes[1, 1].imshow(unstructured_mask, cmap='gray')
    axes[1, 1].set_title('éç»“æ„åŒ–å‰ªææ©ç ')

    # è¡Œç»“æ„åŒ–å‰ªæ
    axes[0, 2].imshow(row_structured_result, cmap='RdBu', vmin=-2, vmax=2)
    axes[0, 2].set_title('è¡Œç»“æ„åŒ–å‰ªæç»“æœ')
    axes[1, 2].imshow(row_mask, cmap='gray')
    axes[1, 2].set_title('è¡Œç»“æ„åŒ–å‰ªææ©ç ')

    # åˆ—ç»“æ„åŒ–å‰ªæ
    axes[0, 3].imshow(col_structured_result, cmap='RdBu', vmin=-2, vmax=2)
    axes[0, 3].set_title('åˆ—ç»“æ„åŒ–å‰ªæç»“æœ')
    axes[1, 3].imshow(col_mask, cmap='gray')
    axes[1, 3].set_title('åˆ—ç»“æ„åŒ–å‰ªææ©ç ')

    plt.tight_layout()
    plt.savefig('/Users/peixingxin/code/spring2025-lectures/æ·±åº¦è®¨è®º/å‰ªææ¨¡å¼å¯¹æ¯”.png', dpi=150, bbox_inches='tight')
    plt.show()

    return {
        'original': weight,
        'unstructured': unstructured_result,
        'row_structured': row_structured_result,
        'col_structured': col_structured_result
    }

# è¿è¡Œå¯è§†åŒ–
results = visualize_pruning_patterns()
```

## ğŸ› ï¸ PyTorchå‰ªæAPIè¯¦è§£

### 1. åŸºç¡€å‰ªææ–¹æ³•

```python
def pytorch_pruning_methods():
    """PyTorchå‰ªææ–¹æ³•è¯¦è§£"""

    # åˆ›å»ºæµ‹è¯•æ¨¡å‹
    model = nn.Sequential(
        nn.Linear(10, 5),
        nn.ReLU(),
        nn.Linear(5, 1)
    )

    # === éç»“æ„åŒ–å‰ªææ–¹æ³• ===

    # L1éç»“æ„åŒ–å‰ªæï¼ˆåŸºäºL1èŒƒæ•°ï¼‰
    prune.l1_unstructured(model[0], name='weight', amount=0.2)
    print("=== L1éç»“æ„åŒ–å‰ªæ ===")
    print(f"ç¬¬ä¸€å±‚æƒé‡ç¨€ç–åº¦: {1.0 - torch.sum(model[0].weight_mask).item() / model[0].weight_mask.numel():.2%}")

    # éšæœºéç»“æ„åŒ–å‰ªæ
    prune.random_unstructured(model[2], name='weight', amount=0.3)
    print(f"ç¬¬ä¸‰å±‚æƒé‡ç¨€ç–åº¦: {1.0 - torch.sum(model[2].weight_mask).item() / model[2].weight_mask.numel():.2%}")

    # === ç»“æ„åŒ–å‰ªææ–¹æ³• ===

    # Lnç»“æ„åŒ–å‰ªæï¼ˆæŒ‰é€šé“ï¼‰
    prune.ln_structured(model[0], name='weight', amount=0.2, n=2, dim=0)
    print("\n=== Lnç»“æ„åŒ–å‰ªæ ===")
    print("ç¬¬ä¸€å±‚æƒé‡æ©ç :")
    print(model[0].weight_mask)

    # === è‡ªå®šä¹‰å‰ªæ ===

    def custom_prune(module, name, amount):
        """è‡ªå®šä¹‰å‰ªæå‡½æ•°"""
        tensor = getattr(module, name)
        # åŸºäºç»å¯¹å€¼å¤§å°è¿›è¡Œå‰ªæ
        threshold = torch.quantile(torch.abs(tensor), amount)
        mask = torch.abs(tensor) > threshold
        return mask

    # åº”ç”¨è‡ªå®šä¹‰å‰ªæ
    custom_mask = custom_prune(model[2], 'weight', 0.2)
    prune.custom_from_mask(model[2], 'weight', custom_mask)

    return model
```

### 2. å‰ªæçš„æ°¸ä¹…åŒ–å’Œç§»é™¤

```python
def pruning_permanence():
    """å‰ªæçš„æ°¸ä¹…åŒ–å’Œç§»é™¤æœºåˆ¶"""

    linear = nn.Linear(4, 4)
    prune.l1_unstructured(linear, 'weight', 0.5)

    print("=== å‰ªæåçš„çŠ¶æ€ ===")
    print(f"weight: {linear.weight.data}")
    print(f"weight_mask: {linear.weight_mask}")
    print(f"weight_orig: {linear.weight_orig}")

    # ç§»é™¤å‰ªæé‡å‚æ•°åŒ–ï¼ˆä½¿å‰ªææ°¸ä¹…åŒ–ï¼‰
    prune.remove(linear, 'weight')

    print("\n=== ç§»é™¤é‡å‚æ•°åŒ–å ===")
    print(f"weight: {linear.weight.data}")
    print(f" hasattr weight_mask: {hasattr(linear, 'weight_mask')}")
    print(f" hasattr weight_orig: {hasattr(linear, 'weight_orig')}")

    # ç§»é™¤åï¼Œå‰ªææ•ˆæœæ°¸ä¹…ä¿å­˜åœ¨weightä¸­
    sparsity = 1.0 - torch.sum(linear.weight != 0).item() / linear.weight.numel()
    print(f"æ°¸ä¹…åŒ–ç¨€ç–åº¦: {sparsity:.2%}")

pruning_permanence()
```

## ğŸ“Š æ€§èƒ½å½±å“åˆ†æ

### 1. å†…å­˜å’Œè®¡ç®—å½±å“

```python
def pruning_performance_analysis():
    """å‰ªæçš„æ€§èƒ½å½±å“åˆ†æ"""

    # åˆ›å»ºä¸åŒè§„æ¨¡çš„å±‚
    sizes = [(100, 100), (500, 500), (1000, 1000)]
    pruning_ratios = [0.0, 0.2, 0.5, 0.8, 0.9]

    results = {}

    for size in sizes:
        rows, cols = size
        results[size] = {}

        for ratio in pruning_ratios:
            # åˆ›å»ºæƒé‡
            weight = torch.randn(rows, cols)

            # éç»“æ„åŒ–å‰ªæ
            mask_unstructured = torch.random.random(size) > ratio
            weight_unstructured = weight * mask_unstructured

            # ç»“æ„åŒ–å‰ªæï¼ˆæŒ‰è¡Œï¼‰
            n_rows = int(rows * ratio)
            if n_rows > 0:
                row_indices = torch.randperm(rows)[:n_rows]
                mask_structured = torch.ones(size, dtype=torch.bool)
                mask_structured[row_indices, :] = False
            else:
                mask_structured = torch.ones(size, dtype=torch.bool)

            weight_structured = weight * mask_structured

            # è®¡ç®—æŒ‡æ ‡
            results[size][ratio] = {
                'unstructured_sparsity': 1.0 - torch.sum(mask_unstructured).item() / mask_unstructured.numel(),
                'structured_sparsity': 1.0 - torch.sum(mask_structured).item() / mask_structured.numel(),
                'unstructured_nonzeros': torch.sum(weight_unstructured != 0).item(),
                'structured_nonzeros': torch.sum(weight_structured != 0).item(),
                'unstructured_flops': 2 * torch.sum(mask_unstructured).item(),  # ä¹˜åŠ æ“ä½œ
                'structured_flops': 2 * rows * cols * (1 - ratio)  # æ•´è¡Œåˆ é™¤
            }

    # æ‰“å°ç»“æœ
    print("=== å‰ªææ€§èƒ½åˆ†æ ===")
    for size in sizes:
        print(f"\nçŸ©é˜µè§„æ¨¡: {size}")
        print(f"{'å‰ªææ¯”ä¾‹':<10} {'éç»“æ„åŒ–ç¨€ç–åº¦':<15} {'ç»“æ„åŒ–ç¨€ç–åº¦':<15} {'éç»“æ„åŒ–FLOP':<15} {'ç»“æ„åŒ–FLOP':<15}")
        print("-" * 80)

        for ratio in pruning_ratios:
            result = results[size][ratio]
            print(f"{ratio:<10.1f} {result['unstructured_sparsity']:<15.2%} {result['structured_sparsity']:<15.2%} "
                  f"{result['unstructured_flops']:<15.0f} {result['structured_flops']:<15.0f}")

    return results

pruning_performance_analysis()
```

### 2. å®é™…æ¨ç†é€Ÿåº¦æµ‹è¯•

```python
def inference_speed_benchmark():
    """æ¨ç†é€Ÿåº¦åŸºå‡†æµ‹è¯•"""

    import time

    # åˆ›å»ºæµ‹è¯•æ•°æ®
    batch_size = 100
    input_size = 1000
    output_size = 1000

    x = torch.randn(batch_size, input_size)

    # åŸå§‹å¯†é›†å±‚
    linear_dense = nn.Linear(input_size, output_size)

    # éç»“æ„åŒ–å‰ªæå±‚
    linear_unstructured = nn.Linear(input_size, output_size)
    linear_unstructured.weight.data = linear_dense.weight.data.clone()
    prune.l1_unstructured(linear_unstructured, 'weight', amount=0.8)
    prune.remove(linear_unstructured, 'weight')  # æ°¸ä¹…åŒ–

    # ç»“æ„åŒ–å‰ªæå±‚ï¼ˆæ¨¡æ‹Ÿï¼‰
    linear_structured = nn.Linear(int(input_size * 0.2), int(output_size * 0.2))  # ä¿ç•™20%

    # é¢„çƒ­
    for _ in range(10):
        _ = linear_dense(x)
        _ = linear_unstructured(x)
        _ = linear_structured(x[:, :int(input_size * 0.2)])

    # åŸºå‡†æµ‹è¯•
    num_runs = 100

    # å¯†é›†å±‚
    start_time = time.time()
    for _ in range(num_runs):
        _ = linear_dense(x)
    dense_time = time.time() - start_time

    # éç»“æ„åŒ–å‰ªæå±‚
    start_time = time.time()
    for _ in range(num_runs):
        _ = linear_unstructured(x)
    unstructured_time = time.time() - start_time

    # ç»“æ„åŒ–å‰ªæå±‚
    start_time = time.time()
    for _ in range(num_runs):
        _ = linear_structured(x[:, :int(input_size * 0.2)])
    structured_time = time.time() - start_time

    print("=== æ¨ç†é€Ÿåº¦å¯¹æ¯” ===")
    print(f"å¯†é›†å±‚æ¨ç†æ—¶é—´: {dense_time:.4f}s")
    print(f"éç»“æ„åŒ–å‰ªææ¨ç†æ—¶é—´: {unstructured_time:.4f}s (åŠ é€Ÿ {dense_time/unstructured_time:.2f}x)")
    print(f"ç»“æ„åŒ–å‰ªææ¨ç†æ—¶é—´: {structured_time:.4f}s (åŠ é€Ÿ {dense_time/structured_time:.2f}x)")

    return {
        'dense': dense_time,
        'unstructured': unstructured_time,
        'structured': structured_time
    }

inference_speed_benchmark()
```

## ğŸ¯ å®è·µåº”ç”¨æŒ‡å—

### 1. å‰ªæç­–ç•¥é€‰æ‹©

```python
def pruning_strategy_guide():
    """å‰ªæç­–ç•¥é€‰æ‹©æŒ‡å—"""

    strategies = {
        'æ¸è¿›å¼å‰ªæ': {
            'æè¿°': 'é€æ­¥å¢åŠ å‰ªææ¯”ä¾‹ï¼Œè®©æ¨¡å‹é€‚åº”',
            'é€‚ç”¨åœºæ™¯': 'é«˜ç²¾åº¦è¦æ±‚çš„ä»»åŠ¡',
            'å®ç°æ–¹å¼': 'åˆ†é˜¶æ®µå‰ªæï¼Œæ¯é˜¶æ®µå¾®è°ƒ',
            'ä¼˜åŠ¿': 'ç²¾åº¦æŸå¤±å°',
            'åŠ£åŠ¿': 'è®­ç»ƒæ—¶é—´é•¿'
        },

        'ä¸€æ¬¡æ€§å‰ªæ': {
            'æè¿°': 'ä¸€æ¬¡æ€§è¾¾åˆ°ç›®æ ‡ç¨€ç–åº¦',
            'é€‚ç”¨åœºæ™¯': 'å¿«é€ŸåŸå‹éªŒè¯',
            'å®ç°æ–¹å¼': 'ç›´æ¥å‰ªæåˆ°ç›®æ ‡æ¯”ä¾‹',
            'ä¼˜åŠ¿': 'å®ç°ç®€å•å¿«é€Ÿ',
            'åŠ£åŠ¿': 'ç²¾åº¦æŸå¤±å¤§'
        },

        'è¿­ä»£å¼å‰ªæ': {
            'æè¿°': 'å‰ªæ-æ¢å¤-å†å‰ªæçš„å¾ªç¯è¿‡ç¨‹',
            'é€‚ç”¨åœºæ™¯': 'æ¢ç´¢æœ€ä¼˜å‰ªææ¨¡å¼',
            'å®ç°æ–¹å¼': 'å¤šè½®å‰ªæå’Œå¾®è°ƒ',
            'ä¼˜åŠ¿': 'å¯èƒ½æ‰¾åˆ°æ›´å¥½è§£',
            'åŠ£åŠ¿': 'è®¡ç®—æˆæœ¬é«˜'
        }
    }

    return strategies

def gradual_pruning_example():
    """æ¸è¿›å¼å‰ªæç¤ºä¾‹"""

    class GradualPruning:
        def __init__(self, model, initial_sparsity=0.0, final_sparsity=0.8, num_steps=10):
            self.model = model
            self.initial_sparsity = initial_sparsity
            self.final_sparsity = final_sparsity
            self.num_steps = num_steps
            self.current_step = 0

        def step(self):
            """æ‰§è¡Œä¸€æ­¥æ¸è¿›å¼å‰ªæ"""
            if self.current_step >= self.num_steps:
                return

            # è®¡ç®—å½“å‰æ­¥éª¤çš„ç¨€ç–åº¦
            progress = self.current_step / self.num_steps
            current_sparsity = self.initial_sparsity + (self.final_sparsity - self.initial_sparsity) * progress

            # å¯¹æ¨¡å‹çš„æ‰€æœ‰çº¿æ€§å±‚è¿›è¡Œå‰ªæ
            for module in self.model.modules():
                if isinstance(module, nn.Linear):
                    if hasattr(module, 'weight_mask'):
                        # æ›´æ–°ç°æœ‰å‰ªæ
                        prune.remove(module, 'weight')

                    prune.l1_unstructured(module, 'weight', amount=current_sparsity)

            self.current_step += 1
            print(f"Step {self.current_step}/{self.num_steps}: ç¨€ç–åº¦ = {current_sparsity:.2%}")

        def finalize(self):
            """æ°¸ä¹…åŒ–å‰ªæ"""
            for module in self.model.modules():
                if isinstance(module, nn.Linear) and hasattr(module, 'weight_mask'):
                    prune.remove(module, 'weight')

    # ä½¿ç”¨ç¤ºä¾‹
    model = nn.Sequential(nn.Linear(100, 50), nn.ReLU(), nn.Linear(50, 10))
    gradual_pruner = GradualPruning(model, initial_sparsity=0.0, final_sparsity=0.8, num_steps=5)

    print("=== æ¸è¿›å¼å‰ªæè¿‡ç¨‹ ===")
    for _ in range(5):
        gradual_pruner.step()

    gradual_pruner.finalize()
    print("å‰ªæå®Œæˆå¹¶æ°¸ä¹…åŒ–")

gradual_pruning_example()
```

### 2. å‰ªæçš„æœ€ä½³å®è·µ

```python
def pruning_best_practices():
    """å‰ªææœ€ä½³å®è·µ"""

    checklist = {
        'å‰ªæå‰å‡†å¤‡': [
            'â–¡ è¯„ä¼°åŸå§‹æ¨¡å‹åŸºå‡†æ€§èƒ½',
            'â–¡ åˆ†ææ¨¡å‹ç»“æ„å’Œé‡è¦æ€§',
            'â–¡ ç¡®å®šå‰ªæç›®æ ‡å’Œçº¦æŸ',
            'â–¡ å‡†å¤‡å¾®è°ƒæ•°æ®é›†',
            'â–¡ é€‰æ‹©åˆé€‚çš„å‰ªæç­–ç•¥'
        ],

        'å‰ªæè¿‡ç¨‹': [
            'â–¡ ä»å°æ¯”ä¾‹å¼€å§‹è¯•éªŒ',
            'â–¡ ç›‘æ§ç²¾åº¦å˜åŒ–è¶‹åŠ¿',
            'â–¡ ä¿ç•™é‡è¦æƒé‡ï¼ˆå¦‚æ³¨æ„åŠ›æƒé‡ï¼‰',
            'â–¡ è€ƒè™‘å±‚é—´ç¨€ç–åº¦å·®å¼‚',
            'â–¡ åŠæ—¶å¾®è°ƒæ¢å¤ç²¾åº¦'
        ],

        'å‰ªæåä¼˜åŒ–': [
            'â–¡ å¾®è°ƒæ¨¡å‹æ¢å¤ç²¾åº¦',
            'â–¡ é‡åŒ–è¿›ä¸€æ­¥å‹ç¼©',
            'â–¡ çŸ¥è¯†è’¸é¦æå‡æ€§èƒ½',
            'â–¡ ç¡¬ä»¶å…¼å®¹æ€§æµ‹è¯•',
            'â–¡ éƒ¨ç½²æ€§èƒ½éªŒè¯'
        ],

        'å¸¸è§é™·é˜±é¿å…': [
            'â–¡ é¿å…è¿‡åº¦å‰ªæå¯¼è‡´ç²¾åº¦å´©æºƒ',
            'â–¡ æ³¨æ„å‰ªæåçš„æ¢¯åº¦æµé—®é¢˜',
            'â–¡ è€ƒè™‘ä¸åŒå±‚çš„é‡è¦æ€§å·®å¼‚',
            'â–¡ éªŒè¯å‰ªæçš„å®é™…åŠ é€Ÿæ•ˆæœ',
            'â–¡ ä¿æŒå‰ªæçš„å¯é‡ç°æ€§'
        ]
    }

    return checklist

# å®é™…åº”ç”¨ç¤ºä¾‹
def real_world_pruning_pipeline():
    """å®é™…é¡¹ç›®çš„å‰ªææµæ°´çº¿"""

    def prune_model_for_mobile(model, dataset, target_sparsity=0.8):
        """ä¸ºç§»åŠ¨ç«¯è®¾å¤‡å‰ªææ¨¡å‹çš„å®Œæ•´æµæ°´çº¿"""

        # 1. è¯„ä¼°åŸå§‹æ¨¡å‹
        print("=== 1. è¯„ä¼°åŸå§‹æ¨¡å‹ ===")
        original_accuracy = evaluate_model(model, dataset)
        original_size = calculate_model_size(model)
        print(f"åŸå§‹ç²¾åº¦: {original_accuracy:.2%}")
        print(f"åŸå§‹å¤§å°: {original_size:.2f} MB")

        # 2. åˆ†æå±‚é‡è¦æ€§
        print("\n=== 2. åˆ†æå±‚é‡è¦æ€§ ===")
        layer_importance = analyze_layer_importance(model, dataset)
        for layer_name, importance in layer_importance.items():
            print(f"{layer_name}: {importance:.3f}")

        # 3. è‡ªé€‚åº”å‰ªæ
        print("\n=== 3. è‡ªé€‚åº”å‰ªæ ===")
        for name, module in model.named_modules():
            if isinstance(module, nn.Linear):
                # æ ¹æ®å±‚é‡è¦æ€§è°ƒæ•´å‰ªææ¯”ä¾‹
                layer_importance = layer_importance.get(name, 1.0)
                adaptive_sparsity = target_sparsity * (1.0 - layer_importance * 0.3)

                prune.l1_unstructured(module, 'weight', amount=adaptive_sparsity)
                print(f"{name}: å‰ªææ¯”ä¾‹ {adaptive_sparsity:.2%}")

        # 4. å¾®è°ƒæ¢å¤ç²¾åº¦
        print("\n=== 4. å¾®è°ƒæ¢å¤ç²¾åº¦ ===")
        fine_tuned_model = fine_tune_pruned_model(model, dataset, epochs=10)
        pruned_accuracy = evaluate_model(fine_tuned_model, dataset)
        print(f"å‰ªæåç²¾åº¦: {pruned_accuracy:.2%}")
        print(f"ç²¾åº¦æŸå¤±: {(1 - pruned_accuracy/original_accuracy)*100:.2f}%")

        # 5. æ°¸ä¹…åŒ–å’Œä¼˜åŒ–
        print("\n=== 5. æ°¸ä¹…åŒ–å’Œä¼˜åŒ– ===")
        for module in fine_tuned_model.modules():
            if isinstance(module, nn.Linear) and hasattr(module, 'weight_mask'):
                prune.remove(module, 'weight')

        # 6. æœ€ç»ˆéªŒè¯
        final_size = calculate_model_size(fine_tuned_model)
        compression_ratio = original_size / final_size
        print(f"æœ€ç»ˆå¤§å°: {final_size:.2f} MB")
        print(f"å‹ç¼©æ¯”: {compression_ratio:.2f}x")

        return fine_tuned_model

    return prune_model_for_mobile

print("=== å‰ªææŠ€æœ¯æ€»ç»“ ===")
print("1. éç»“æ„åŒ–å‰ªæ: é›¶æ•£ç½®é›¶ï¼Œç²¾åº¦é«˜ä½†ç¡¬ä»¶ä¸å‹å¥½")
print("2. ç»“æ„åŒ–å‰ªæ: æ•´ä½“åˆ é™¤ï¼Œç¡¬ä»¶å‹å¥½ä½†ç²¾åº¦æŸå¤±å¤§")
print("3. æ¸è¿›å¼å‰ªæ: é€æ­¥é€‚åº”ï¼Œå¹³è¡¡ç²¾åº¦å’Œå‹ç¼©")
print("4. è‡ªé€‚åº”å‰ªæ: æ ¹æ®é‡è¦æ€§å·®å¼‚åŒ–å‰ªæ")
```

## ğŸ” æ·±åº¦æ€è€ƒï¼šå‰ªæçš„æœ¬è´¨

å‰ªææŠ€æœ¯çš„æ ¸å¿ƒä»·å€¼åœ¨äº**åˆ©ç”¨ç¥ç»ç½‘ç»œçš„å†—ä½™æ€§**ï¼š

1. **å‚æ•°å†—ä½™**: æ·±åº¦ç½‘ç»œé€šå¸¸å‚æ•°è¿‡å¤šï¼Œå­˜åœ¨å¤§é‡å†—ä½™
2. **ç»“æ„å†—ä½™**: æŸäº›ç¥ç»å…ƒæˆ–é€šé“å¯¹æœ€ç»ˆè´¡çŒ®å¾ˆå°
3. **åŠŸèƒ½å†—ä½™**: ä¸åŒè·¯å¾„å¯èƒ½å­¦ä¹ ç›¸ä¼¼çš„ç‰¹å¾

**æˆåŠŸçš„å‰ªæ = å‡†ç¡®çš„å†—ä½™è¯†åˆ« + åˆé€‚çš„å‰ªæç­–ç•¥ + ç²¾ç»†çš„å¾®è°ƒæ¢å¤**

---

**ğŸ’¡ æ ¸å¿ƒæ´å¯Ÿ**: å‰ªæä¸ä»…æ˜¯æ¨¡å‹å‹ç¼©æŠ€æœ¯ï¼Œæ›´æ˜¯ç†è§£ç¥ç»ç½‘ç»œå†…éƒ¨å·¥ä½œåŸç†çš„é‡è¦å·¥å…·ã€‚é€šè¿‡åˆ†æå“ªäº›å‚æ•°å¯ä»¥è¢«å®‰å…¨ç§»é™¤ï¼Œæˆ‘ä»¬å¯ä»¥æ·±å…¥ç†è§£ç½‘ç»œçš„å­¦ä¹ æœºåˆ¶å’Œç‰¹å¾è¡¨ç¤ºã€‚